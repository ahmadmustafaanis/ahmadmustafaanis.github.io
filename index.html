<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ahmad Mustafa Anis</title>

    <meta name="author" content="Ahmad Mustafa Anis">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ahmad Mustafa Anis
                </p>
                <p>I'm a Deep Learning Computer Vision Engineer at <a href="https://roll.ai">Roll.ai</a>. I completed my Bachelors in Computer Science from International Islamic University Pakistan, advised by <a href="https://scholar.google.com.pk/citations?user=XiR3-tMAAAAJ&hl=en">Dr. Muhammad Nadeem</a>.
                </p>
                <p>
                  I was an AI Fellow at the 14th Batch of <a href="https://picampus-school.com/programme/school-of-artificial-intelligence/">PI School of AI</a> with a scholarship worth 12,500€.
                </p>
                <p>
                  I serve as a community lead (For Geo-Regional Asia and ML-Maths Subgroups) at <a href="https://cohere.for.ai">Cohere.for.ai</a>, led by <a href="https://twitter.com/sarahookr">Sara Hooker</a>. In this role, I've hosted over 50 researchers from Asia to present their work at <a href="https://www.youtube.com/playlist?list=PLLalUvky4CLJKDaiWCumhsJpHNDhZeVll">Cohere for AI</a>, completed a study group on <a href="https://atcold.github.io/NYU-DLSP21/">NYU Deep Learning</a> by Yann LeCun.
                </p>

                <!-- <p>
                  I am looking for PhD positions in CS for F-25. If my profile interests you, feel free to reach out.
                </p> -->

                <p>
                See my Resume <a href="https://drive.google.com/file/d/1TNJdiFV0ZsvwNns77Bw-BN2IRNTMGOO0/view?usp=drivesdk">here </a> (Updated June 2024).
                </p>

                <p style="text-align:center">
                  <a href="mailto:ahmadanis5050@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/AhmadMustafaAn1">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=58X2MYsAAAAJ&hl=en">Google Scholar</a>
                  <a href="http://huggingface.co/AhmadMustafa">Hugging Face</a> &nbsp;/&nbsp;

                  <a href="https://github.com/ahmadmustafaanis">Github</a> &nbsp;/&nbsp;
                  <a href="https://medium.com/@ahmadanis5050">Medium</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ahmad-mustafa-anis/">Linkedin</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/me3.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/me3.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am interested in Deep Learning in general, and read literature from different fields. In-particular, I try to follow the research in the following areas:
                  <ul>
                    <li>
                        Improving Reasoning in Vision and Language Models
                        <ul>
                            <li>Visual Question Answering (VQA)</li>
                            <ul>
                              How well can a model reason on an image/video and answer questions.
                            </ul>
                            <li>Image Generation</li>
                            <ul>
                            How well can a model reasonate with the textual caption and generate image.
                            </ul>

                        </ul>
                    </li>
                    <li>Self-Supervised Learning</li>
                    <ul>
                      How to learn good representations from a huge amount of data that can be used for down-stream tasks without huge efforts.
                    </ul>
                    <li>World Models</li>
                    <ul>
                      How can we make models that can plan and reason in an environment.
                    </ul>
                </ul>
                  
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>News</h2>
              <p></p>
            <li>[July 2024] Our work on <a href="https://arxiv.org/abs/2407.14933">"The Rapid Decline of the AI Data Commons"</a> has been published</li>
            <li>
              [June, 2024] Serving as NLP Lead for <a href="https://www.bytewiseltd.com/fellowship">Bytewise Fellowship</a>.</b>.
            </li>
            <li>
              [April, 2024] Accepted in <b>Oxford Machine Learning Summer School OxML (MLX Fundamentals)</b>.
            </li>
            <li>
              [April, 2024] Started working as a <b>Deep Learning Computer Vision Engineer</b> at <a href="https://roll.ai">Roll.ai</a>.
            </li>
            <li>
              [Dec, 2023] Got accepted as <b>AI Fellow</b> at the 14th Batch of <a href="https://picampus-school.com/programme/school-of-artificial-intelligence/"> <b>PI School of AI</b></a> with a scholarship worth 12,500€.
            </li>
            <li>
              [Dec, 2023] Started as a <b>ML-Maths Community Lead</b> at <a href="https://cohere.for.ai">Cohere.for.ai</a> led by <a href="https://twitter.com/sarahookr">Sara Hooker</a>.
            </li>
            <li>
              [June, 2023] Served as <b>Urdu Language Ambassador</b> for <b><a href="https://arxiv.org/abs/2402.06619"><b>AYA</b></a></b>. <a href="https://huggingface.co/AhmadMustafa">Contributed 3 Datasets</a> and led data crowd sourcing. 
            </li>
            <li>
              [Mar, 2023] Serving as Data Science Lead for <a href="https://www.bytewiseltd.com/fellowship">Bytewise Fellowship</a>.</b>. 
            </li>

            <li>
              [Feb, 2023] Started as a <b>Asian Community Lead</b> at <a href="https://cohere.for.ai">Cohere.for.ai</a> led by <a href="https://twitter.com/sarahookr">Sara Hooker</a>. See our sessions: <a href="https://www.youtube.com/playlist?list=PLLalUvky4CLJKDaiWCumhsJpHNDhZeVll"><b>here</b></a>.
            </li>
            <li>[Aug, 2022] Graduated from <b>IIUI</b> with a Bachelors in Computer Science.</li>

            <li>[April, 2022] Started as a <b>Machine Learning Engineer</b> at <b><a href="https://redbuffer.ai">Redbuffer.ai</a></b>.</li>

            <li>[Dec, 2021] Started as a <b>Software Engineer (Deep Learning and Computer Vision)</b> at <b><a href="https://wortel.ai">Wortel.ai</a></b>.</li>

            <li>[July, 2021] Started as a <b>Deep Learning and Computer Vision Intern</b> at <b><a href="https://wortel.ai">Wortel.ai</a></b>.</li>
            <li>[Sep, 2018] Started my Undergraduate studies in CS at <a href="https://www.iiu.edu.pk/">IIUI</a></li>

          </td>

            </tr>
            <!-- <tr>
          

            </tr> -->
          </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Publications</h2>
                  <div class="publication-container">
                    <img class="publication-image" src="/Users/ahmadanis/Desktop/Screenshot 2024-07-26 at 12.56.58 AM.png" alt="Consent in Crisis">
                    <div class="publication-content">
                      <div class="publication-title">Consent in Crisis: The Rapid Decline of the AI Data Commons</div>
                      <div class="publication-authors">
                        Shayne Longpre, Robert Mahari, Ariel Lee, Campbell Lund, [11 authors], <strong>Ahmad Mustafa Anis</strong>, [29 more authors], Daphne Ippolito, Sara Hooker, Jad Kabbara, and Sandy Pentland
                      </div>
                      <div class="publication-venue">NeurIPS, 2024 (Under review)</div>
                      <div class="publication-links">
                        <a href="https://www.dataprovenance.org/">Project page</a>/ <a href="https://arxiv.org/abs/2407.14933">arXiv</a>
                      </div>
                      <div class="publication-description">
                        This paper examines the rapid decline of consent and data availability in AI training corpora, highlighting the challenges and implications for the AI data commons.
                      </div>
                    </div>
                  </div>
                          <!-- Second paper (new addition) -->
                  <!-- <div class="publication-container">
                    <img class="publication-image" src="/path/to/second/paper/image.jpg" alt="Second Paper Title">
                    <div class="publication-content">
                      <div class="publication-title">Title of Your Second Paper</div>
                      <div class="publication-authors">
                        Author 1, Author 2, <strong>Ahmad Mustafa Anis</strong>, Author 3, Author 4
                      </div>
                      <div class="publication-venue">Conference/Journal Name, Year</div>
                      <div class="publication-links">
                        <a href="#">project page</a> / <a href="#">video</a> / <a href="#">arXiv</a>
                      </div>
                      <div class="publication-description">
                        Brief description of your second paper goes here.
                      </div>
                    </div>
                  </div> -->

                </td>
              </tr>
              
            </tbody>
          </table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Favourite Papers</h2>
              <p>
                List of papers I really admire (and hope to do similar impactful work).
              </p>
            <li>
              <b>CLIP</b>, <a href="https://arxiv.org/abs/2103.00020">abs</a>
            </li>
            <li>
              <b>World Models</b>, <a href="https://arxiv.org/abs/1803.10122">abs</a>
            </li>
            <li>
              <b>JEPA</b>, <a href="https://arxiv.org/abs/2301.08243">abs</a>
            </li>
            <li>
              <b>SimCLR</b>,
              <a href="https://arxiv.org/abs/2002.05709">abs</a>
            </li>
            <li>
              <b>Vision Transformers Need Registers</b>,
              <a href="https://arxiv.org/abs/2309.16588">abs</a>
            </li>
            <li>
              <b>Pali-3</b>,
              <a href="https://arxiv.org/abs/2310.09199">abs</a>
              
            </li>
            <li>
              <b>Learning by Distilling Context</b>,
              <a href="https://arxiv.org/abs/2209.15189">abs</a>
            </li>
            <li>
              <b>SigLIP</b>,
              <a href="https://arxiv.org/abs/2303.15343">abs</a>
            </li>
            <li><b>GILL: Generating Images with Multimodal Language Models</b>,
              <a href="https://arxiv.org/abs/2305.17216">abs</a>
            </li>
            

          </td>

            </tr>
            <!-- <tr>
          

            </tr> -->
          </tbody>
          </table>
          
          
            <!-- <tr>
          

            </tr> -->
          </tbody>
          </table>
          
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Code from Jon Barron <a href="https://github.com/jonbarron/jonbarron_website">Website</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
